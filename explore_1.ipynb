{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ab9389c",
   "metadata": {},
   "source": [
    "This notebook is intended to explore the NEOs dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37e6a3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9abb7785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "howdy\n"
     ]
    }
   ],
   "source": [
    "print(\"howdy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab22552e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>est_diameter_min</th>\n",
       "      <th>est_diameter_max</th>\n",
       "      <th>relative_velocity</th>\n",
       "      <th>miss_distance</th>\n",
       "      <th>orbiting_body</th>\n",
       "      <th>sentry_object</th>\n",
       "      <th>absolute_magnitude</th>\n",
       "      <th>hazardous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2162635</td>\n",
       "      <td>162635 (2000 SS164)</td>\n",
       "      <td>1.198271</td>\n",
       "      <td>2.679415</td>\n",
       "      <td>13569.249224</td>\n",
       "      <td>5.483974e+07</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>16.73</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2277475</td>\n",
       "      <td>277475 (2005 WK4)</td>\n",
       "      <td>0.265800</td>\n",
       "      <td>0.594347</td>\n",
       "      <td>73588.726663</td>\n",
       "      <td>6.143813e+07</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>20.00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2512244</td>\n",
       "      <td>512244 (2015 YE18)</td>\n",
       "      <td>0.722030</td>\n",
       "      <td>1.614507</td>\n",
       "      <td>114258.692129</td>\n",
       "      <td>4.979872e+07</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>17.83</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3596030</td>\n",
       "      <td>(2012 BV13)</td>\n",
       "      <td>0.096506</td>\n",
       "      <td>0.215794</td>\n",
       "      <td>24764.303138</td>\n",
       "      <td>2.543497e+07</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>22.20</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3667127</td>\n",
       "      <td>(2014 GE35)</td>\n",
       "      <td>0.255009</td>\n",
       "      <td>0.570217</td>\n",
       "      <td>42737.733765</td>\n",
       "      <td>4.627557e+07</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>20.09</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                 name  est_diameter_min  est_diameter_max  \\\n",
       "0  2162635  162635 (2000 SS164)          1.198271          2.679415   \n",
       "1  2277475    277475 (2005 WK4)          0.265800          0.594347   \n",
       "2  2512244   512244 (2015 YE18)          0.722030          1.614507   \n",
       "3  3596030          (2012 BV13)          0.096506          0.215794   \n",
       "4  3667127          (2014 GE35)          0.255009          0.570217   \n",
       "\n",
       "   relative_velocity  miss_distance orbiting_body  sentry_object  \\\n",
       "0       13569.249224   5.483974e+07         Earth          False   \n",
       "1       73588.726663   6.143813e+07         Earth          False   \n",
       "2      114258.692129   4.979872e+07         Earth          False   \n",
       "3       24764.303138   2.543497e+07         Earth          False   \n",
       "4       42737.733765   4.627557e+07         Earth          False   \n",
       "\n",
       "   absolute_magnitude  hazardous  \n",
       "0               16.73      False  \n",
       "1               20.00       True  \n",
       "2               17.83      False  \n",
       "3               22.20      False  \n",
       "4               20.09       True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neos = pd.read_csv(\"neo.csv\")\n",
    "neos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3465638d",
   "metadata": {},
   "source": [
    "Normalizing the features may be the best approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0fac920f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of num hazardous =  9.731824386806993 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "neos[\"sentry_object\"] = neos[\"sentry_object\"].astype(int)\n",
    "neos[\"hazardous\"] = neos[\"hazardous\"].astype(int)\n",
    "features_df = neos[\n",
    "    [\n",
    "        \"est_diameter_min\",\n",
    "        \"est_diameter_max\",\n",
    "        \"relative_velocity\",\n",
    "        \"miss_distance\",\n",
    "        \"sentry_object\",\n",
    "        \"absolute_magnitude\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# relative_velocity = neos[\"relative_velocity\"]\n",
    "# miss_distance = neos[\"miss_distance\"]\n",
    "\n",
    "target = neos[\"hazardous\"].values\n",
    "features = features_df.values\n",
    "X = features\n",
    "y = target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=9524\n",
    ")\n",
    "\n",
    "total_num_hazardous = np.sum(target)\n",
    "print(\"percentage of num hazardous = \", (total_num_hazardous / len(target)) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eebf6ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8989982386613826\n"
     ]
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "unscaled_score = model.score(X_test, y_test)\n",
    "print(unscaled_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf4efdd",
   "metadata": {},
   "source": [
    "89% accuracy on non-scaled data. Can we do better by scaling this with a minmax scaler?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "901e428a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9006494936151476\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = linear_model.LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "score = model.score(X_test_scaled, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d69bcf",
   "metadata": {},
   "source": [
    "Hmmmm. 90.5%? That doesn't seem like much of an improvement.... Right. Accuracy score only measures correct predictions. Since 90% of the data is classified as nonhazardous, it makes a lot of sense how the unscaled model made its predictions. It might be better to look at metrics like f1 score, recall, and precision. \n",
    "\n",
    "\n",
    "Precision - of all predicted hazardous NEOs, how many really are hazardous?\n",
    "\n",
    "Recall - of all truly hazardous NEOs, how many did we catch?\n",
    "\n",
    "F1 score - Harmonic mean with precision and recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2f0e7b",
   "metadata": {},
   "source": [
    "Let's start with unscaled data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d8caf108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of unscaled X_test:  0.313953488372093\n",
      "Recall of unscaled X_test:  0.014975041597337771\n",
      "f1_score of unscaled X_test 0.028586553732133403\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "precision = metrics.precision_score\n",
    "recall = metrics.recall_score\n",
    "f1 = metrics.f1_score\n",
    "\n",
    "y_hat_from_unscaled = model.predict(X_test)\n",
    "\n",
    "print(\n",
    "    \"Precision of unscaled X_test: \",\n",
    "    precision(y_true=y_test, y_pred=y_hat_from_unscaled),\n",
    ")\n",
    "print(\"Recall of unscaled X_test: \", recall(y_true=y_test, y_pred=y_hat_from_unscaled))\n",
    "\n",
    "print(\"f1_score of unscaled X_test\", f1(y_true=y_test, y_pred=y_hat_from_unscaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9212b1b6",
   "metadata": {},
   "source": [
    "Ahh. This makes more sense. The model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2ddcda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of scaled X_test:  0.21204280842055745\n",
      "Recall of scaled X_test:  1.0\n",
      "f1_score of scaled X_test 0.34989326605860666\n"
     ]
    }
   ],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "\n",
    "y_hat_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Precision of scaled X_test: \", precision(y_true=y_test, y_pred=y_hat_scaled))\n",
    "print(\"Recall of scaled X_test: \", recall(y_true=y_test, y_pred=y_hat_scaled))\n",
    "print(\"f1_score of scaled X_test\", f1(y_true=y_test, y_pred=y_hat_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3175fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90268175613193\n"
     ]
    }
   ],
   "source": [
    "baseline_accuracy = max(np.mean(y), 1 - np.mean(y))\n",
    "\n",
    "print(baseline_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4ccbe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
